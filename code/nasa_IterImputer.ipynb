{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from plotnine import *\n",
    "from IPython.display import display\n",
    "\n",
    "# Machine Learning\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "from scipy.cluster import hierarchy as hc\n",
    "from fastai.imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(93, 29)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data = pd.read_csv('etc/data/lownoise/nasa93dem.csv')\n",
    "data = pd.read_csv('etc/data/highnoise/nasa93dem.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "idX             1\n",
       "centerX         2\n",
       "YearX        1979\n",
       "prec            h\n",
       "flex            h\n",
       "resl            h\n",
       "team           vh\n",
       "pmat            h\n",
       "rely            h\n",
       "data            l\n",
       "cplx            h\n",
       "ruse            n\n",
       "docu            ?\n",
       "time            n\n",
       "stor            n\n",
       "pvol            l\n",
       "acap            n\n",
       "pcap            n\n",
       "pcon            n\n",
       "apex            n\n",
       "plex            n\n",
       "ltex            h\n",
       "tool            n\n",
       "site            n\n",
       "sced            l\n",
       "Kloc+        25.9\n",
       "Effort-     117.6\n",
       "Defects-      808\n",
       "Months-      15.3\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "imp = IterativeImputer(max_iter=10, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['39', '2', '1986', 'h', 'h', 'h', 'vh', 'n', 'n', 'n', 'h', 'n',\n",
       "       'n', 'n', 'n', 'n', 'n', 'n', 'n', nan, 'n', 'n', 'n', 'n', 'n',\n",
       "       8.0, 42.0, 420, 12.5], dtype=object)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.replace('?', np.nan, inplace=True)\n",
    "datanp = data.to_numpy()\n",
    "datanp[38]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoders = {}\n",
    "for idx in range(3,25): \n",
    "    encoders[idx] = LabelEncoder()\n",
    "    encod_data = encoders[idx].fit_transform(datanp[:,idx])\n",
    "    datanp[:,idx] = encod_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['h' nan]\n",
      "['h' nan]\n",
      "['h' nan]\n",
      "['vh' nan]\n",
      "['h' 'l' 'n' nan]\n",
      "['h' 'l' 'n' 'vh']\n",
      "['h' 'l' 'n' 'vh' nan]\n",
      "['h' 'l' 'n' 'vh' 'xh' nan]\n",
      "['n' nan]\n",
      "['n' nan]\n",
      "['h' 'n' 'vh' 'xh' nan]\n",
      "['h' 'n' 'vh' 'xh' nan]\n",
      "['h' 'l' 'n' nan]\n",
      "['h' 'n' 'vh' nan]\n",
      "['h' 'n' 'vh' nan]\n",
      "['n' nan]\n",
      "['h' 'l' 'n' 'vh' nan]\n",
      "['h' 'l' 'n' 'vl' nan]\n",
      "['h' 'l' 'n' 'vl' nan]\n",
      "['h' 'n' nan]\n",
      "['n' nan]\n",
      "['l' 'n' nan]\n"
     ]
    }
   ],
   "source": [
    "for i in range(3,25):\n",
    "    print(encoders[i].classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addnan(encoder , datanp, col):\n",
    "    classes1 = list(encoder.classes_)\n",
    "    if np.nan in classes1:\n",
    "        id = classes1.index(np.nan)\n",
    "        for i,value in enumerate(datanp[:,col]):\n",
    "            if value == id:\n",
    "                datanp[i][col] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(3,25):\n",
    "    addnan(encoders[idx] , datanp, idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataimp = imp.fit_transform(datanp)\n",
    "dataimp[:,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0,\n",
       "       0, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, nan, 2, 0, 2, 2, 0, 0, 0, 0,\n",
       "       2, nan, 0, 0, 1, 1, nan, 1, 1, 1, 1, 0, 0, 0, 1, nan, 0, 0, 2, 2,\n",
       "       2, nan, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 2, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 2, 2, 2], dtype=object)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datanp[:,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        2.,  2.,  2.,  2.,  2.,  2.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  0.,  1.,  0.,  0.,  1.,  0.,  0.,  0.,  1.,  0.,  0., -0.,\n",
       "        0.,  1.,  1.,  2.,  0.,  1.,  0.,  2.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0., -0.,  0.,  0.,  0.,  0.,  0.,  0., -0.,  0.,\n",
       "        0.,  0.,  1.,  0.,  2.,  2.,  0.,  0., -0.,  0.,  0.,  0.,  1.,\n",
       "        1.,  1.])"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataimp[:,16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataimp[:,:-4] = np.round(dataimp[:,:-4])\n",
    "dataimp[:,-2] = np.round(dataimp[:,-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0, 2.0, 1979.0, ..., 117.6, 808.0, 15.3],\n",
       "       [2.0, 2.0, 1979.0, ..., 117.6, 767.0, 15.0],\n",
       "       [3.0, 2.0, 1979.0, ..., 31.2, 240.0, 10.1],\n",
       "       ...,\n",
       "       [91.0, 2.0, 1981.0, ..., 480.0, 1253.0, 21.5],\n",
       "       [92.0, 2.0, 1983.0, ..., 12.0, 477.0, 15.4],\n",
       "       [93.0, 2.0, 1983.0, ..., 38.0, 231.0, 12.0]], dtype=object)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = dataimp[:,:3]\n",
    "for idx in range(3,25):\n",
    "    decode = encoders[idx].inverse_transform(dataimp[:,idx].astype(np.int32))\n",
    "    res = np.column_stack((res, decode))\n",
    "res = np.column_stack((res, dataimp[:,25:]))\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnew = pd.DataFrame(res, columns=data.columns)\n",
    "#dfnew.to_csv(\"iter_low_nasa.csv\", index=False)\n",
    "dfnew.to_csv(\"iter_high_nasa.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
